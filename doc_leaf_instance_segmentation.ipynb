{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Leaf Instance Segmentation using maskRCNN (with a pre-trained model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instance segmentation is identifying each object instance for every known object within an image. Instance segmentation assigns a label to each pixel of the image. It can be used for tasks such as counting the number of objects. \n",
    "\n",
    "Instance segmentation requires:\n",
    "\n",
    "1. Object detection of all objects in an image. For object detection, the goal is to classify individual objects and localize each object instance using a bounding box.\n",
    "2. Segmenting each instance. For segmentation the goal is to classify each pixel into a fixed set of categories without differentiating object instances. \n",
    "\n",
    "Taking an image of an arabidopsis plant as an example. As shown in the image below, the 1st image is an RGB image of an arabidopsis. There are two categories present in this image: (arabidopsis) plant and background. The image in the middle is an example of objection segmentation result, the pixels considered to be object (plant) are detected and segmented out. The 3rd image is the result of instance segmentation. \n",
    "\n",
    "\n",
    "<table><tr>\n",
    "<td> <img src=\"doc_img/original.jpg\" alt=\"Drawing\" width=\"250\"/> </td>\n",
    "<td> <img src=\"doc_img/threshold.jpg\" alt=\"Drawing\" style=\"width: 250px;\"/> </td>\n",
    "<td> <img src=\"doc_img/instance_seg.jpg\" alt=\"Drawing\" style=\"width: 250px;\"/> </td>    \n",
    "</tr></table>\n",
    "\n",
    "It is easy to tell that the goal for image segmentation is to have pixel level labels indicating \"plant\" or \"not plant\" for every pixel, and the output for image segmentation is a binary mask indicating where the plant is in the image. At this point we have no information regarding number of leaves in this image. \n",
    "\n",
    "While for instance segmentation, as shown in the 3rd image, we can see that the goal is to segment out every leaf (hence, there is a label for every leaf, e.g. leaf 1, leaf 2, etc.) instance. In this specific example, 5 binary masks would be generated, every one represents for one leaf. Hence we are also able to tell that there are 5 leaves present in this image. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are plenty of methods for instance segmentation, arabidopsis leaf instance segmentation using maskRCNN is shown here as an example. \n",
    "\n",
    "For detailed information regrading maskRCNN, please check here:\n",
    "https://github.com/matterport/Mask_RCNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installation of maskRCNN to your PC or workstation\n",
    "Follow the installation steps to create a conda environment for mask_rcnn and install necessary packages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Create a conda environment with tensorflow 1.13.1 and keras 2.1.0.\n",
    "    - Open a terminal window, type:\n",
    "    ```\n",
    "    conda create -n mrcnn tensorflow=1.13.1\n",
    "    conda activate mrcnn\n",
    "    pip install keras==2.1.0\n",
    "    conda install plantcv # install plantcv tools for this environment\n",
    "```\n",
    "This would create a tensorflow environment (with tensorflow 1.13.1 and keras 2.1.0, those are required by the MaskRCNN package we are to install) with a name of mrcnn. You are free to change the name \"mrcnn\" based on you own preference. \n",
    "\n",
    "- Install MaskRCNN\n",
    "    - Clone [this](https://github.com/matterport/Mask_RCNN) github repository to your desired location. (It is suggested to put the same directory as you put your plantcv folder)\n",
    "    - Open a terminal, follow the instructions below:\n",
    "    \n",
    "```\n",
    "    cd Mask_RCNN # direct yourself to the folder of Mask_RCNN\n",
    "    pip install -r requirements.txt # install dependencies\n",
    "    python3 setup.py install # run setup\n",
    "```   \n",
    "\n",
    "After you finish setting up this conda environment and package installation, you can clone [this](https://github.com/danforthcenter/plantcv-tutorial_leaf_instance_segmentation) repository with test images included. And use this notebook to test on test images or your own images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try our interactive tutorial!\n",
    "Alternatively, you can also refer to this interactive tutorial: \n",
    "[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/danforthcenter/plantcv-tutorial_leaf_instance_segmentation/a5a0c08aa9b2d8d3db078a58cec3b64d0a9f8ccf?filepath=doc_leaf_instance_segmentation.ipynb)\n",
    "https://mybinder.org/v2/gh/danforthcenter/plantcv-tutorial_leaf_instance_segmentation/16583a0748a17c8d1fe93cb8ff14276caea01f6d\n",
    "And you can explore the repository [here](https://mybinder.org/v2/gh/danforthcenter/plantcv-tutorial_leaf_instance_segmentation/master). (Note: If you would like to upload your own test images, you should use this link to upload images, and open this \"doc_leaf_instance_segmentation.ipynb\" notebook.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With conda environment mrcnn activated (```conda activate mrcnn```), you are ready to get instance level segmentation with Mask_RCNN using a pre-trained model. Follow the step below to download this pre-trained model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "179179456"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "url        = 'https://datasci.danforthcenter.org/mask_rcnn_leaves_0060.h5'\n",
    "name_model = 'model.h5'\n",
    "open('./{}'.format(name_model), 'wb').write(requests.get(url).content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point you will find a file called \"model.h5\" in the current folder. \n",
    "\n",
    "Now you can follow this notebook for step-by-step implementation of leaf instance segmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hsheng/miniconda3/envs/mrcnn/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/hsheng/miniconda3/envs/mrcnn/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/hsheng/miniconda3/envs/mrcnn/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/hsheng/miniconda3/envs/mrcnn/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/hsheng/miniconda3/envs/mrcnn/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/hsheng/miniconda3/envs/mrcnn/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# import packages \n",
    "import os\n",
    "import inferencing_utilities as funcs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instance segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following block is where you want to change based on your own application:\n",
    "\n",
    "Some detailed regarding parameters \"suffix\":\n",
    "The image names in the \"test_img\" folder either end with \"img11.jpg\" or \"img17.jpg\", and in this specific case different numbers represent for different plants. To make sure we include same plant for the experiment, we have to define the plant by the parameter \"suffix\". The example here shows the analysis for plant 17."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## suffix of original image files. Make sure that all files have the same suffix format\n",
    "suffix = 'crop-img17.jpg'\n",
    "\n",
    "## pattern for the date-tima part in your data. Make sure that the date-time part in all filenames follow the same pattern\n",
    "pattern_datetime = '\\d{4}-\\d{2}-\\d{2}-\\d{2}-\\d{2}'\n",
    "\n",
    "## directory of original images\n",
    "imagedir = 'test_img'\n",
    "\n",
    "## desired saving directory for results\n",
    "savedir = 'segmentation'\n",
    "if not os.path.exists(savedir):\n",
    "    os.makedirs(savedir)\n",
    "\n",
    "## class names. Since a pre-trained model is used here, and the model is trained with 2 classes: either \"Background\" or \"Leaf\", there is really nothing to change here\n",
    "class_names = ['BG', 'Leaf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/hsheng/miniconda3/envs/mrcnn/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/hsheng/miniconda3/envs/mrcnn/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:1208: calling reduce_max_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /home/hsheng/miniconda3/envs/mrcnn/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:1242: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /home/hsheng/miniconda3/envs/mrcnn/lib/python3.7/site-packages/mask_rcnn-2.1-py3.7.egg/mrcnn/model.py:772: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Loading weights  /shares/mgehan_share/hsheng/plantcv-tutorial_leaf_instance_segmentation/model.h5\n",
      "There are 12 images.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['10.9.1.241_pos-165-003-020_2019-10-22-11-05_crop-img17.jpg',\n",
       " '10.9.1.241_pos-165-003-020_2019-10-23-11-05_crop-img17.jpg',\n",
       " '10.9.1.241_pos-165-003-020_2019-10-24-11-05_crop-img17.jpg',\n",
       " '10.9.1.241_pos-165-003-020_2019-10-25-11-05_crop-img17.jpg',\n",
       " '10.9.1.241_pos-165-003-020_2019-10-26-11-05_crop-img17.jpg',\n",
       " '10.9.1.241_pos-165-003-020_2019-10-27-11-05_crop-img17.jpg',\n",
       " '10.9.1.241_pos-165-003-020_2019-10-28-11-05_crop-img17.jpg',\n",
       " '10.9.1.241_pos-165-003-020_2019-10-29-11-05_crop-img17.jpg',\n",
       " '10.9.1.241_pos-165-003-020_2019-10-30-11-05_crop-img17.jpg',\n",
       " '10.9.1.241_pos-165-003-020_2019-10-31-11-05_crop-img17.jpg',\n",
       " '10.9.1.241_pos-165-003-020_2019-11-01-11-05_crop-img17.jpg',\n",
       " '10.9.1.241_pos-165-003-020_2019-11-02-11-05_crop-img17.jpg']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Root directory of the project\n",
    "rootdir = os.path.abspath(\"./\")\n",
    "\n",
    "## initialize the instance segmentation\n",
    "instance_seg =  funcs.instance_seg_inferencing(imagedir, savedir, rootdir, pattern_datetime, suffix, class_names)\n",
    "\n",
    "## get configuration for instance segmentation\n",
    "instance_seg.get_configure()\n",
    "\n",
    "## load the pre-trained model\n",
    "instance_seg.load_model()\n",
    "\n",
    "## pre-define colors for visualization used later\n",
    "instance_seg.define_colors()\n",
    "\n",
    "## get the list of all files\n",
    "instance_seg.get_file_list()\n",
    "\n",
    "## option (print the file list)\n",
    "instance_seg.list_f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the next block, a randomly selected example is used to show the instance segmentation result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## show one randomly selected image as an example\n",
    "instance_seg.inferencing_random_sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is an automated \"segmentation quality control\" inside the model. For every given image, after the initial segmentation, it will check the overlaps of every two segmentation masks to see whether there exists either of the two types of the issues defined below:\n",
    "Issue 1: two segmentation masks heavily overlap each other\n",
    "    In this case, the segmentation mask with higher segmentation score would be kept\n",
    "Issue 2: one mask (mask a) overlaps with two or more other masks (mask b, mask c, etc.)\n",
    "    In this case, mask a would be removed\n",
    "The message printed out indicates the change of segmentation before and after quality control. If you found the number of instances before and after quality control are not the same, the segmentation result was updated. And you will see two sets of visualizations. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you run the following block, it will loop over all files in the file list you defined. Note it might take some time for the process to finish.\n",
    "\n",
    "You can also explore the sample results here: \\\n",
    "result/segmentation/2020-07-27-12-37/segmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "\n",
      "...\n",
      "\n",
      "Processing 1 images\n",
      "image                    shape: (501, 500, 3)         min:    0.00000  max:  166.00000  uint8\n",
      "molded_images            shape: (1, 1024, 1024, 3)    min: -123.70000  max:   47.20000  float64\n",
      "image_metas              shape: (1, 14)               min:    0.00000  max: 1024.00000  float64\n",
      "anchors                  shape: (1, 261888, 4)        min:   -0.08847  max:    1.02591  float32\n",
      "1 image done. Which is 1\n",
      "\n",
      "Processing 1 images\n",
      "image                    shape: (499, 501, 3)         min:    0.00000  max:  171.00000  uint8\n",
      "molded_images            shape: (1, 1024, 1024, 3)    min: -123.70000  max:   52.20000  float64\n",
      "image_metas              shape: (1, 14)               min:    0.00000  max: 1024.00000  float64\n",
      "anchors                  shape: (1, 261888, 4)        min:   -0.08847  max:    1.02591  float32\n",
      "2 images done. The last one is 10.9.1.241_pos-165-003-020_2019-10-23-11-05_crop-img17.jpg\n",
      "\n",
      "Processing 1 images\n",
      "image                    shape: (499, 499, 3)         min:    0.00000  max:  173.00000  uint8\n",
      "molded_images            shape: (1, 1024, 1024, 3)    min: -123.70000  max:   54.20000  float64\n",
      "image_metas              shape: (1, 14)               min:    0.00000  max: 1024.00000  float64\n",
      "anchors                  shape: (1, 261888, 4)        min:   -0.08847  max:    1.02591  float32\n",
      "3 images done. The last one is 10.9.1.241_pos-165-003-020_2019-10-24-11-05_crop-img17.jpg\n",
      "\n",
      "Processing 1 images\n",
      "image                    shape: (500, 500, 3)         min:    0.00000  max:  173.00000  uint8\n",
      "molded_images            shape: (1, 1024, 1024, 3)    min: -123.70000  max:   55.20000  float64\n",
      "image_metas              shape: (1, 14)               min:    0.00000  max: 1024.00000  float64\n",
      "anchors                  shape: (1, 261888, 4)        min:   -0.08847  max:    1.02591  float32\n",
      "4 images done. The last one is 10.9.1.241_pos-165-003-020_2019-10-25-11-05_crop-img17.jpg\n",
      "\n",
      "Processing 1 images\n",
      "image                    shape: (500, 500, 3)         min:    0.00000  max:  172.00000  uint8\n",
      "molded_images            shape: (1, 1024, 1024, 3)    min: -123.70000  max:   54.20000  float64\n",
      "image_metas              shape: (1, 14)               min:    0.00000  max: 1024.00000  float64\n",
      "anchors                  shape: (1, 261888, 4)        min:   -0.08847  max:    1.02591  float32\n",
      "5 images done. The last one is 10.9.1.241_pos-165-003-020_2019-10-26-11-05_crop-img17.jpg\n",
      "\n",
      "Processing 1 images\n",
      "image                    shape: (499, 501, 3)         min:    0.00000  max:  173.00000  uint8\n",
      "molded_images            shape: (1, 1024, 1024, 3)    min: -123.70000  max:   54.20000  float64\n",
      "image_metas              shape: (1, 14)               min:    0.00000  max: 1024.00000  float64\n",
      "anchors                  shape: (1, 261888, 4)        min:   -0.08847  max:    1.02591  float32\n",
      "6 images done. The last one is 10.9.1.241_pos-165-003-020_2019-10-27-11-05_crop-img17.jpg\n",
      "\n",
      "Processing 1 images\n",
      "image                    shape: (499, 500, 3)         min:    0.00000  max:  175.00000  uint8\n",
      "molded_images            shape: (1, 1024, 1024, 3)    min: -123.70000  max:   56.20000  float64\n",
      "image_metas              shape: (1, 14)               min:    0.00000  max: 1024.00000  float64\n",
      "anchors                  shape: (1, 261888, 4)        min:   -0.08847  max:    1.02591  float32\n",
      "7 images done. The last one is 10.9.1.241_pos-165-003-020_2019-10-28-11-05_crop-img17.jpg\n",
      "\n",
      "Processing 1 images\n",
      "image                    shape: (501, 501, 3)         min:    0.00000  max:  173.00000  uint8\n",
      "molded_images            shape: (1, 1024, 1024, 3)    min: -123.70000  max:   54.20000  float64\n",
      "image_metas              shape: (1, 14)               min:    0.00000  max: 1024.00000  float64\n",
      "anchors                  shape: (1, 261888, 4)        min:   -0.08847  max:    1.02591  float32\n",
      "8 images done. The last one is 10.9.1.241_pos-165-003-020_2019-10-29-11-05_crop-img17.jpg\n",
      "\n",
      "Processing 1 images\n",
      "image                    shape: (501, 499, 3)         min:    0.00000  max:  171.00000  uint8\n",
      "molded_images            shape: (1, 1024, 1024, 3)    min: -123.70000  max:   53.20000  float64\n",
      "image_metas              shape: (1, 14)               min:    0.00000  max: 1024.00000  float64\n",
      "anchors                  shape: (1, 261888, 4)        min:   -0.08847  max:    1.02591  float32\n",
      "9 images done. The last one is 10.9.1.241_pos-165-003-020_2019-10-30-11-05_crop-img17.jpg\n",
      "\n",
      "Processing 1 images\n",
      "image                    shape: (500, 499, 3)         min:    0.00000  max:  171.00000  uint8\n",
      "molded_images            shape: (1, 1024, 1024, 3)    min: -123.70000  max:   52.20000  float64\n",
      "image_metas              shape: (1, 14)               min:    0.00000  max: 1024.00000  float64\n",
      "anchors                  shape: (1, 261888, 4)        min:   -0.08847  max:    1.02591  float32\n",
      "10 images done. The last one is 10.9.1.241_pos-165-003-020_2019-10-31-11-05_crop-img17.jpg\n",
      "\n",
      "Processing 1 images\n",
      "image                    shape: (501, 501, 3)         min:    0.00000  max:  169.00000  uint8\n",
      "molded_images            shape: (1, 1024, 1024, 3)    min: -123.70000  max:   51.20000  float64\n",
      "image_metas              shape: (1, 14)               min:    0.00000  max: 1024.00000  float64\n",
      "anchors                  shape: (1, 261888, 4)        min:   -0.08847  max:    1.02591  float32\n",
      "11 images done. The last one is 10.9.1.241_pos-165-003-020_2019-11-01-11-05_crop-img17.jpg\n",
      "\n",
      "Processing 1 images\n",
      "image                    shape: (500, 501, 3)         min:    0.00000  max:  219.00000  uint8\n",
      "molded_images            shape: (1, 1024, 1024, 3)    min: -123.70000  max:   88.30000  float64\n",
      "image_metas              shape: (1, 14)               min:    0.00000  max: 1024.00000  float64\n",
      "anchors                  shape: (1, 261888, 4)        min:   -0.08847  max:    1.02591  float32\n",
      "12 images done. The last one is 10.9.1.241_pos-165-003-020_2019-11-02-11-05_crop-img17.jpg\n",
      "\n",
      "Done! \n",
      "The results are saved here: segmentation/2020-09-09-16-05. \n",
      "The visualization are saved here: segmentation/2020-09-09-16-05/visualization.\n",
      "The updated visualization are saved here: segmentation/2020-09-09-16-05/visualization/updated\n"
     ]
    }
   ],
   "source": [
    "## get the result of all images\n",
    "instance_seg.inferencing_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are not in the interactive tutorial (binder), you can direct yourself to this folder to check the saved result by running the following block:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'segmentation/2020-09-09-16-05/visualization'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instance_seg.visualization_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also print out the directory for updated result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'segmentation/2020-09-09-16-05/visualization/updated'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instance_seg.updated_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can compare the segmentation result before and after updates (quality control)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can compare the segmentation result before and after quality control\n",
    "You can also find the \"segmentation_summary.csv\" file in the saving directory (instance_seg.savedir), which summarizes the segmentation by printing out the image names, the issues for every image, the number of segments before and after quality control."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
